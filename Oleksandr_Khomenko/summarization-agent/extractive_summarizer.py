"""Extractive summarization module using deterministic methods."""

import nltk
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lsa import LsaSummarizer
from sumy.summarizers.lex_rank import LexRankSummarizer
from sumy.summarizers.luhn import LuhnSummarizer
from nltk.tokenize import sent_tokenize
from typing import List, Dict, Any

class ExtractiveSummarizer:
    """Deterministic extractive summarization class that extracts key sentences."""
    
    def __init__(self, ratio: float = 0.2, min_length: int = 40):
        """Initialize the extractive summarizer.
        
        Args:
            ratio: The proportion of the original text to keep in the summary
            min_length: Minimum length of sentences to consider for summarization
        """
        self.ratio = ratio
        self.min_length = min_length
        self.summarizers = {
            'lsa': LsaSummarizer(),
            'lexrank': LexRankSummarizer(),
            'luhn': LuhnSummarizer()
        }
        
        # Ensure NLTK resources are available
        try:
            nltk.data.find('tokenizers/punkt')
        except LookupError:
            nltk.download('punkt')
            
        try:
            nltk.data.find('stopwords')
        except LookupError:
            nltk.download('stopwords')
        
        # Add stopwords to summarizers
        for summarizer in self.summarizers.values():
            summarizer.stop_words = nltk.corpus.stopwords.words('english')
            
    def _filter_sentences(self, text: str) -> List[str]:
        """Filter sentences by minimum length.
        
        Args:
            text: The input text
            
        Returns:
            List of sentences that meet the minimum length requirement
        """
        sentences = sent_tokenize(text)
        return [s for s in sentences if len(s) >= self.min_length]
    
    def _determine_sentence_count(self, sentences: List[str]) -> int:
        """Determine how many sentences to keep based on the ratio.
        
        Args:
            sentences: List of sentences
            
        Returns:
            Number of sentences to keep
        """
        count = max(1, int(len(sentences) * self.ratio))
        return min(count, len(sentences))  # Ensure we don't exceed the sentence count
    
    def summarize(self, text: str, method: str = 'lexrank') -> Dict[str, Any]:
        """Generate an extractive summary from the input text.
        
        Args:
            text: The text to summarize
            method: The summarization method to use ('lsa', 'lexrank', or 'luhn')
            
        Returns:
            Dictionary containing the summary and metadata
        """
        if method not in self.summarizers:
            method = 'lexrank'  # Default to LexRank if invalid method provided
            
        # Filter sentences by length
        filtered_sentences = self._filter_sentences(text)
        
        if not filtered_sentences:
            return {
                'summary': text,
                'method': method,
                'sentences_selected': 0,
                'total_sentences': 0,
                'ratio': 1.0
            }
        
        # Parse the text
        parser = PlaintextParser.from_string(text, Tokenizer("english"))
        
        # Determine the number of sentences to keep
        sentence_count = self._determine_sentence_count(filtered_sentences)
        
        # Generate the summary
        summarizer = self.summarizers[method]
        summary_sentences = summarizer(parser.document, sentence_count)
        
        # Join the selected sentences
        summary = " ".join(str(sentence) for sentence in summary_sentences)
        
        return {
            'summary': summary,
            'method': method,
            'sentences_selected': len(summary_sentences),
            'total_sentences': len(filtered_sentences),
            'ratio': len(summary_sentences) / len(filtered_sentences) if filtered_sentences else 1.0
        }
    
    def summarize_all_methods(self, text: str) -> Dict[str, Dict[str, Any]]:
        """Generate summaries using all available methods.
        
        Args:
            text: The text to summarize
            
        Returns:
            Dictionary of summaries generated by each method
        """
        return {method: self.summarize(text, method) for method in self.summarizers.keys()}
        
    def get_best_summary(self, text: str) -> Dict[str, Any]:
        """Generate summaries using all methods and return the best one.
        
        The 'best' summary is determined by the one with the highest ratio of important keywords
        preserved from the original text.
        
        Args:
            text: The text to summarize
            
        Returns:
            Dictionary containing the best summary and metadata
        """
        summaries = self.summarize_all_methods(text)
        
        # Default to LexRank if we can't determine a better one
        return summaries.get('lexrank', next(iter(summaries.values())))
