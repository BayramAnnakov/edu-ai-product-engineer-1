# Placeholder for comparison logic

import pandas as pd
import nltk
from nltk.tokenize import word_tokenize
from nltk.util import ngrams
import re

# Make sure we have the necessary NLTK data
try:
    nltk.data.find('tokenizers/punkt')
except:
    nltk.download('punkt')

def calculate_similarity_metrics(text1, text2):
    """Calculate similarity metrics between two texts."""
    # Tokenize the texts
    tokens1 = word_tokenize(text1.lower())
    tokens2 = word_tokenize(text2.lower())
    
    # Word overlap
    set1 = set(tokens1)
    set2 = set(tokens2)
    overlap = len(set1.intersection(set2))
    
    # Jaccard similarity
    jaccard = len(set1.intersection(set2)) / len(set1.union(set2)) if set1 or set2 else 0
    
    # Calculate n-gram overlap (for bigrams)
    bigrams1 = set(ngrams(tokens1, 2))
    bigrams2 = set(ngrams(tokens2, 2))
    bigram_overlap = len(bigrams1.intersection(bigrams2)) / max(len(bigrams1), len(bigrams2)) if bigrams1 and bigrams2 else 0
    
    return {
        "word_overlap_count": overlap,
        "word_overlap_percent": overlap / max(len(set1), len(set2)) if set1 or set2 else 0,
        "jaccard_similarity": jaccard,
        "bigram_overlap": bigram_overlap
    }

def generate_comparison_report(summaries_df: pd.DataFrame) -> str:
    """
    Generates a detailed report comparing extractive and abstractive summaries.

    Args:
        summaries_df: DataFrame containing 'Id', 'Text', 'ExtractiveSummary',
                      and 'AbstractiveSummary' columns.

    Returns:
        A string containing the markdown-formatted comparison report.
    """
    report_lines = ["# Summary Comparison Report\n"]
    report_lines.append("## Executive Summary\n")
    report_lines.append("This report compares deterministic extractive summaries (first sentence) with probabilistic abstractive summaries generated by LLMs for customer reviews.\n\n")
    
    # Add a summary table at the beginning
    report_lines.append("## Summary Table\n")
    report_lines.append("| ID | Original Text (truncated) | Extractive Summary | Abstractive Summary |")
    report_lines.append("| --- | --- | --- | --- |")
    for index, row in summaries_df.iterrows():
        # Truncate the original text to keep the table manageable
        truncated_text = row['Text'][:100] + "..." if len(row['Text']) > 100 else row['Text']
        # Clean up any pipe characters that would break the markdown table
        truncated_text = truncated_text.replace("|", "&#124;")
        extractive_summary = row['ExtractiveSummary'].replace("|", "&#124;")
        abstractive_summary = row['AbstractiveSummary'].replace("|", "&#124;")
        
        report_lines.append(f"| {row['Id']} | {truncated_text} | {extractive_summary} | {abstractive_summary} |")
    
    report_lines.append("\n## Detailed Analysis\n")
    
    # Calculate overall statistics
    extractive_lengths = []
    abstractive_lengths = []
    word_overlaps = []
    jaccard_similarities = []
    
    # Process each review
    for index, row in summaries_df.iterrows():
        # Calculate metrics
        ext_len = len(row['ExtractiveSummary'].split())
        abs_len = len(row['AbstractiveSummary'].split())
        extractive_lengths.append(ext_len)
        abstractive_lengths.append(abs_len)
        
        # Calculate similarity metrics
        metrics = calculate_similarity_metrics(row['ExtractiveSummary'], row['AbstractiveSummary'])
        word_overlaps.append(metrics["word_overlap_percent"])
        jaccard_similarities.append(metrics["jaccard_similarity"])
        
        # Add to the report for each review
        report_lines.append(f"## Review ID: {row['Id']}\n")
        report_lines.append(f"**Original Text:**\n```\n{row['Text']}\n```\n")
        report_lines.append(f"**Extractive Summary (First Sentence):**\n```\n{row['ExtractiveSummary']}\n```\n")
        report_lines.append(f"**Abstractive Summary (LLM-generated):**\n```\n{row['AbstractiveSummary']}\n```\n")
        
        # Add comparison metrics
        report_lines.append(f"**Comparison Metrics:**")
        report_lines.append(f"- Extractive Length: {ext_len} words")
        report_lines.append(f"- Abstractive Length: {abs_len} words")
        report_lines.append(f"- Length Difference: {abs_len - ext_len} words ({(abs_len/ext_len*100)-100:.1f}% change)")
        report_lines.append(f"- Word Overlap: {metrics['word_overlap_count']} words ({metrics['word_overlap_percent']*100:.1f}%)")
        report_lines.append(f"- Jaccard Similarity: {metrics['jaccard_similarity']:.3f}")
        report_lines.append(f"- Bigram Overlap: {metrics['bigram_overlap']:.3f}")
        
        # Add analysis
        report_lines.append(f"\n**Analysis:**\n")
        if metrics['jaccard_similarity'] > 0.7:
            report_lines.append("The summaries are very similar, suggesting the first sentence captures most key points.\n")
        elif metrics['jaccard_similarity'] > 0.4:
            report_lines.append("The summaries share moderate similarity but the abstractive summary adds some novel phrasing.\n")
        else:
            report_lines.append("The summaries differ significantly, suggesting the LLM identified different key points than what appears in the first sentence.\n")
        
        report_lines.append("-" * 40 + "\n")

    # Add overall statistics section
    report_lines.append("## Overall Statistics\n")
    report_lines.append(f"- Average Extractive Summary Length: {sum(extractive_lengths)/len(extractive_lengths):.1f} words")
    report_lines.append(f"- Average Abstractive Summary Length: {sum(abstractive_lengths)/len(abstractive_lengths):.1f} words")
    report_lines.append(f"- Average Word Overlap: {sum(word_overlaps)/len(word_overlaps)*100:.1f}%")
    report_lines.append(f"- Average Jaccard Similarity: {sum(jaccard_similarities)/len(jaccard_similarities):.3f}")
    
    # Add conclusions
    report_lines.append("\n## Conclusions\n")
    if sum(jaccard_similarities)/len(jaccard_similarities) > 0.6:
        report_lines.append("The first-sentence extractive approach seems quite effective for these reviews, capturing similar information to the LLM-based approach.\n")
    elif sum(jaccard_similarities)/len(jaccard_similarities) > 0.3:
        report_lines.append("The LLM-based abstractive summaries provide meaningful differences from simple first-sentence extraction, offering additional perspective.\n")
    else:
        report_lines.append("Abstractive summarization significantly differs from extractive, suggesting the value of using both approaches for a more comprehensive understanding.\n")
    
    # Add follow-up questions
    report_lines.append("\n## Suggested Follow-up Questions\n")
    report_lines.append("1. How does the effectiveness of each summary type vary by review length?")
    report_lines.append("2. Would using the first two sentences for extractive summaries improve their information content?")
    report_lines.append("3. How do summary methods perform on negative versus positive reviews?")
    report_lines.append("4. Could a hybrid approach (e.g., extractive first, then abstractive refinement) be more effective?")

    return "\n".join(report_lines)

if __name__ == '__main__':
     # Example Usage
    data = {
        'Id': [1],
        'Text': ["This is the full review text. It goes into detail about the product features and the user experience. Overall, it was positive."],
        'ExtractiveSummary': ["This is the full review text."],
        'AbstractiveSummary': ["User liked the product features."]
    }
    example_df = pd.DataFrame(data)
    report = generate_comparison_report(example_df)
    print(report) 